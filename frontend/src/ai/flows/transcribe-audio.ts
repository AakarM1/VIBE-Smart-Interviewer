// This is an autogenerated file from Firebase Genkit.
'use server';
/**
 * @fileOverview This file defines a Genkit flow for transcribing audio data.
 *
 * - transcribeAudio - A function that takes audio data as input and returns a transcription.
 * - TranscribeAudioInput - The input type for the transcribeAudio function.
 * - TranscribeAudioOutput - The return type for the transcribeAudio function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import {TRANSCRIPTION_MODEL} from '@/ai/config';

const TranscribeAudioInputSchema = z.object({
  audioDataUri: z
    .string()
    .describe(
      "The audio data to transcribe, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'"
    ),
});

export type TranscribeAudioInput = z.infer<typeof TranscribeAudioInputSchema>;

const TranscribeAudioOutputSchema = z.object({
  transcription: z.string().describe('The transcription of the audio data.'),
});

export type TranscribeAudioOutput = z.infer<typeof TranscribeAudioOutputSchema>;

export async function transcribeAudio(input: TranscribeAudioInput): Promise<TranscribeAudioOutput> {
  return transcribeAudioFlow(input);
}

const transcribeAudioPrompt = ai.definePrompt({
  name: 'transcribeAudioPrompt',
  input: {schema: TranscribeAudioInputSchema},
  output: {schema: TranscribeAudioOutputSchema},
  model: TRANSCRIPTION_MODEL, // Use model from centralized config
  prompt: `You are a highly accurate audio transcription service. Your only task is to transcribe the following audio file. Do not add any commentary or introductory text. Provide only the transcribed text.

Audio for transcription: {{media url=audioDataUri}}`,
});

const transcribeAudioFlow = ai.defineFlow(
  {
    name: 'transcribeAudioFlow',
    inputSchema: TranscribeAudioInputSchema,
    outputSchema: TranscribeAudioOutputSchema,
  },
  async input => {
    try {
      console.log(`ðŸ¤– Using ${TRANSCRIPTION_MODEL} for transcription`);
      const {output} = await transcribeAudioPrompt(input);
      console.log("Transcription completed successfully");
      return output!;
    } catch (error: any) {
      console.error("Transcription error:", error);
      
      // Fallback if model fails
      const errorMessage = String(error);
      if (errorMessage.includes('Service Unavailable') || errorMessage.includes('overloaded')) {
        console.log("Attempting fallback transcription with default model");
        
        // Return a basic response to avoid breaking the flow
        return {
          transcription: "Transcription failed due to model overload. Please try again later or use text input instead."
        };
      }
      
      // Re-throw any other errors
      throw error;
    }
  }
);
